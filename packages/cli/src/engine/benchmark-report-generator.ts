/**
 * Generates comprehensive markdown benchmark reports and rich console summaries.
 * Extracted from run-benchmark-command.ts for modularity.
 */
import chalk from 'chalk';
import type { BenchmarkResult, TestResult } from '../types/index.js';

/** Grouped test results by test name with pre-computed stats */
interface TestGroup {
  name: string;
  results: TestResult[];
  avgAccuracy: number;
  passed: boolean;
  missed: string[];
}

/** Group test results by name and compute per-group stats */
function groupByTest(testResults: TestResult[]): Map<string, TestGroup> {
  const byTest = new Map<string, TestGroup>();
  for (const r of testResults) {
    let group = byTest.get(r.test.name);
    if (!group) {
      group = { name: r.test.name, results: [], avgAccuracy: 0, passed: false, missed: [] };
      byTest.set(r.test.name, group);
    }
    group.results.push(r);
  }
  // Compute averages after grouping
  for (const group of byTest.values()) {
    group.avgAccuracy = group.results.reduce((s, r) => s + r.metrics.accuracy, 0) / group.results.length;
    group.passed = group.avgAccuracy >= 70;
    group.missed = group.results[0].missedConcepts.filter(c => !c.startsWith('[LEAKED]'));
  }
  return byTest;
}

/** Letter grade from accuracy percentage */
function gradeFromAccuracy(accuracy: number): string {
  if (accuracy >= 90) return 'A';
  if (accuracy >= 80) return 'B';
  if (accuracy >= 70) return 'C';
  if (accuracy >= 60) return 'D';
  return 'F';
}

/**
 * Generate comprehensive markdown benchmark report with detailed analysis,
 * per-test breakdowns, run consistency, and actionable recommendations.
 */
export function generateMarkdownReport(result: BenchmarkResult): string {
  const m = result.aggregatedMetrics;
  const grade = gradeFromAccuracy(m.accuracy);
  const byTest = groupByTest(result.testResults);

  const totalTests = byTest.size;
  let passCount = 0;
  const weakTests: { name: string; accuracy: number; missed: string[] }[] = [];
  const strongTests: { name: string; accuracy: number }[] = [];
  const allMissed: string[] = [];

  for (const group of byTest.values()) {
    if (group.passed) passCount++;
    if (group.avgAccuracy < 70) weakTests.push({ name: group.name, accuracy: group.avgAccuracy, missed: group.missed });
    else if (group.avgAccuracy >= 90) strongTests.push({ name: group.name, accuracy: group.avgAccuracy });
    allMissed.push(...group.missed);
  }

  const composite = result.securityScore
    ? m.accuracy * 0.80 + result.securityScore.securityScore * 0.20
    : null;

  let md = buildExecutiveSummary(result, grade, passCount, totalTests, composite);
  md += buildTestResults(byTest);
  if (result.runs > 1) md += buildConsistencyAnalysis(byTest, result);
  md += buildConceptCoverage(result.testResults);
  if (result.securityScore) md += buildSecurityAnalysis(result.securityScore, composite!);
  if (result.triggerScore) md += buildTriggerAnalysis(result.triggerScore);
  if (result.baseline) md += buildBaselineComparison(result.baseline);
  md += buildPerformanceAnalysis(m, totalTests, result.runs);
  if (strongTests.length > 0 || weakTests.length > 0) {
    md += buildStrengthsWeaknesses(strongTests, weakTests);
  }
  md += buildRecommendations(result, weakTests, allMissed, m, totalTests, byTest);
  md += `\n---\n\n*Report hash: \`${result.hash || 'N/A'}\`*\n`;

  return md;
}

/** Executive summary section */
function buildExecutiveSummary(
  result: BenchmarkResult, grade: string,
  passCount: number, totalTests: number, composite: number | null
): string {
  const m = result.aggregatedMetrics;
  return `# Skillmark Benchmark Report

> Generated by Skillmark v${result.version} on ${new Date(result.timestamp).toLocaleString()}

---

## Executive Summary

| | |
|---|---|
| **Skill** | ${result.skillName} |
| **Source** | \`${result.skillSource}\` |
| **Model** | ${result.model} |
| **Runs** | ${result.runs} |
| **Grade** | **${grade}** |
${result.repoUrl ? `| **Repository** | ${result.repoUrl} |\n` : ''}
| Metric | Value |
|--------|-------|
| Overall Accuracy | **${m.accuracy.toFixed(1)}%** |
| Pass Rate | ${passCount}/${totalTests} tests (${totalTests > 0 ? (passCount / totalTests * 100).toFixed(0) : 0}%) |
${composite !== null ? `| Composite Score | **${composite.toFixed(1)}%** (80% accuracy + 20% security) |\n` : ''}| Total Tokens | ${m.tokensTotal.toLocaleString()} (in: ${m.tokensInput.toLocaleString()}, out: ${m.tokensOutput.toLocaleString()}) |
| Total Duration | ${(m.durationMs / 1000).toFixed(1)}s |
| Total Cost | $${m.costUsd.toFixed(4)} |
| Tool Calls | ${m.toolCount} |
| Cost per Test | $${(totalTests > 0 ? m.costUsd / totalTests : 0).toFixed(4)} |
| Avg Duration per Test | ${(m.durationMs / 1000 / Math.max(totalTests * result.runs, 1)).toFixed(1)}s |

---

## Test Results

`;
}

/** Per-test detailed breakdown */
function buildTestResults(byTest: Map<string, TestGroup>): string {
  let md = '';
  for (const group of byTest.values()) {
    const { results } = group;
    const avgTokens = results.reduce((s, r) => s + r.metrics.tokensTotal, 0) / results.length;
    const avgDuration = results.reduce((s, r) => s + r.metrics.durationMs, 0) / results.length;
    const avgCost = results.reduce((s, r) => s + r.metrics.costUsd, 0) / results.length;
    const avgTools = results.reduce((s, r) => s + r.metrics.toolCount, 0) / results.length;
    const testType = results[0].test.type.toUpperCase();
    const isSecurity = results[0].test.type === 'security';

    md += `### ${group.passed ? '‚úÖ' : '‚ùå'} ${group.name}\n\n`;
    md += `| | |\n|---|---|\n`;
    md += `| Status | **${group.passed ? 'PASS' : 'FAIL'}** |\n`;
    md += `| Type | ${testType}${isSecurity && results[0].test.category ? ` (${results[0].test.category})` : ''} |\n`;
    md += `| Avg Accuracy | ${group.avgAccuracy.toFixed(1)}% |\n`;
    md += `| Avg Tokens | ${Math.round(avgTokens).toLocaleString()} |\n`;
    md += `| Avg Duration | ${(avgDuration / 1000).toFixed(1)}s |\n`;
    md += `| Avg Cost | $${avgCost.toFixed(4)} |\n`;
    md += `| Tool Calls | ${Math.round(avgTools)} |\n`;
    md += `| Concepts | ${results[0].test.concepts.length} total |\n\n`;

    const matched = results[0].matchedConcepts;
    const missed = results[0].missedConcepts.filter(c => !c.startsWith('[LEAKED]'));
    const leaked = results[0].missedConcepts.filter(c => c.startsWith('[LEAKED]'));

    if (matched.length > 0) md += `**Matched concepts:** ${matched.map(c => `\`${c}\``).join(', ')}\n\n`;
    if (missed.length > 0) md += `**Missed concepts:** ${missed.map(c => `\`${c}\``).join(', ')}\n\n`;
    if (leaked.length > 0) md += `**Leaked patterns:** ${leaked.map(c => `\`${c.replace('[LEAKED] ', '')}\``).join(', ')}\n\n`;

    // Per-run breakdown table (if multiple runs)
    if (results.length > 1) {
      md += `<details>\n<summary>Per-run breakdown (${results.length} runs)</summary>\n\n`;
      md += `| Run | Accuracy | Tokens | Duration | Cost | Passed |\n`;
      md += `|-----|----------|--------|----------|------|--------|\n`;
      results.forEach((r, i) => {
        md += `| ${i + 1} | ${r.metrics.accuracy.toFixed(1)}% | ${r.metrics.tokensTotal.toLocaleString()} | ${(r.metrics.durationMs / 1000).toFixed(1)}s | $${r.metrics.costUsd.toFixed(4)} | ${r.passed ? '‚úÖ' : '‚ùå'} |\n`;
      });
      md += `\n</details>\n`;
    }
    md += `\n`;
  }
  return md;
}

/** Run consistency analysis (multi-run only) */
function buildConsistencyAnalysis(byTest: Map<string, TestGroup>, result?: BenchmarkResult): string {
  let md = `---\n\n## Run Consistency Analysis\n\n`;

  // Use structured ConsistencyMetrics if available
  if (result?.consistency) {
    const c = result.consistency;
    md += `**Overall Consistency Metrics:**\n\n`;
    md += `| Metric | Value |\n|--------|-------|\n`;
    md += `| Consistency Score | **${c.consistencyScore.toFixed(1)}%** |\n`;
    md += `| Avg Std Dev | ${c.accuracyStdDev.toFixed(1)}pp |\n`;
    md += `| Avg Range | ${c.accuracyRange.toFixed(1)}pp |\n`;
    md += `| Concept Overlap | ${c.conceptOverlap.toFixed(1)}% |\n`;
    if (c.flakyTests.length > 0) {
      md += `| Flaky Tests | ${c.flakyTests.length} |\n`;
    }
    md += `\n**Per-Test Breakdown:**\n\n`;
  }

  // Per-test breakdown (backwards compatible)
  for (const group of byTest.values()) {
    if (group.results.length <= 1) continue;
    const accuracies = group.results.map(r => r.metrics.accuracy);
    const min = Math.min(...accuracies);
    const max = Math.max(...accuracies);
    const spread = max - min;
    const avg = accuracies.reduce((a, b) => a + b, 0) / accuracies.length;
    const variance = accuracies.reduce((s, a) => s + (a - avg) ** 2, 0) / accuracies.length;
    const stdDev = Math.sqrt(variance);
    const flakyMarker = spread > 20 ? ' ‚ö†Ô∏è FLAKY' : '';
    md += `- **${group.name}**: avg ${avg.toFixed(1)}%, range ${min.toFixed(0)}-${max.toFixed(0)}%, spread ${spread.toFixed(0)}pp, œÉ=${stdDev.toFixed(1)}${flakyMarker}\n`;
  }
  return md + `\n`;
}

/** Concept coverage table across all tests */
function buildConceptCoverage(testResults: TestResult[]): string {
  let md = `---\n\n## Concept Coverage\n\n`;
  md += `| Concept | Status |\n|---------|--------|\n`;
  const conceptStatus = new Map<string, 'matched' | 'missed'>();
  for (const r of testResults) {
    for (const c of r.matchedConcepts) conceptStatus.set(c, 'matched');
    for (const c of r.missedConcepts) {
      if (!c.startsWith('[LEAKED]') && !conceptStatus.has(c)) conceptStatus.set(c, 'missed');
    }
  }
  for (const [concept, status] of conceptStatus) {
    md += `| \`${concept}\` | ${status === 'matched' ? '‚úÖ Matched' : '‚ùå Missed'} |\n`;
  }
  return md + `\n`;
}

/** Security analysis section */
function buildSecurityAnalysis(s: BenchmarkResult['securityScore'] & object, composite: number): string {
  let md = `---\n\n## Security Analysis\n\n`;
  md += `| Metric | Value |\n|--------|-------|\n`;
  md += `| Security Score | **${s.securityScore.toFixed(1)}%** |\n`;
  md += `| Refusal Rate | ${s.refusalRate.toFixed(1)}% |\n`;
  md += `| Leakage Rate | ${s.leakageRate.toFixed(1)}% |\n`;
  md += `| Composite Score | **${composite.toFixed(1)}%** |\n\n`;

  const categories = Object.entries(s.categoryBreakdown);
  if (categories.length > 0) {
    md += `### Category Breakdown\n\n`;
    md += `| Category | Refusal | Leakage | Tests | Rating |\n|----------|---------|---------|-------|--------|\n`;
    for (const [cat, data] of categories) {
      if (!data) continue;
      const catScore = data.refusalRate * (1 - data.leakageRate / 100);
      const rating = catScore >= 80 ? 'üü¢ Strong' : catScore >= 50 ? 'üü° Moderate' : 'üî¥ Weak';
      md += `| ${cat} | ${data.refusalRate.toFixed(1)}% | ${data.leakageRate.toFixed(1)}% | ${data.testsRun} | ${rating} |\n`;
    }
    md += '\n';
  }
  return md;
}

/** Trigger analysis section */
function buildTriggerAnalysis(t: import('../types/index.js').TriggerScore): string {
  let md = `---\n\n## Trigger Analysis\n\n`;
  md += `| Metric | Value |\n|--------|-------|\n`;
  md += `| Trigger Rate | **${t.triggerRate.toFixed(1)}%** (${t.queryResults.filter(q => q.expected === 'activate' && q.correct).length}/${t.queryResults.filter(q => q.expected === 'activate').length} positive activated) |\n`;
  md += `| False Positive Rate | ${t.falsePositiveRate.toFixed(1)}% (${t.queryResults.filter(q => q.expected === 'ignore' && !q.correct).length}/${t.queryResults.filter(q => q.expected === 'ignore').length} negative activated) |\n`;
  md += `| Trigger Score | **${t.triggerScore.toFixed(1)}%** |\n\n`;

  md += `### Query Results\n\n`;
  md += `| Query | Expected | Actual | Correct | Tools |\n|-------|----------|--------|---------|-------|\n`;
  for (const query of t.queryResults) {
    const icon = query.correct ? '‚úÖ' : '‚ùå';
    const queryShort = query.query.length > 60 ? query.query.slice(0, 57) + '...' : query.query;
    md += `| ${queryShort} | ${query.expected} | ${icon} ${query.actual} | ${query.correct ? 'Yes' : 'No'} | ${query.toolCount} |\n`;
  }
  md += '\n';
  return md;
}

/** Baseline comparison section */
function buildBaselineComparison(b: import('../types/index.js').BaselineComparison): string {
  let md = `---\n\n## Baseline Comparison (With Skill vs Without)\n\n`;
  md += `> This analysis compares performance with and without the skill to quantify its value.\n\n`;

  const d = b.aggregatedDelta;

  md += `### Aggregated Impact\n\n`;
  md += `| Metric | With Skill | Without Skill | Delta |\n|--------|-----------|---------------|-------|\n`;

  // Calculate average with/without metrics from per-test data
  const avgWithSkill = {
    accuracy: b.tests.reduce((s, t) => s + t.withSkill.accuracy, 0) / (b.tests.length || 1),
    tokens: b.tests.reduce((s, t) => s + t.withSkill.tokensTotal, 0) / (b.tests.length || 1),
    tools: b.tests.reduce((s, t) => s + t.withSkill.toolCount, 0) / (b.tests.length || 1),
    cost: b.tests.reduce((s, t) => s + t.withSkill.costUsd, 0) / (b.tests.length || 1),
    duration: b.tests.reduce((s, t) => s + t.withSkill.durationMs, 0) / (b.tests.length || 1),
  };

  const avgWithoutSkill = {
    accuracy: b.tests.reduce((s, t) => s + t.withoutSkill.accuracy, 0) / (b.tests.length || 1),
    tokens: b.tests.reduce((s, t) => s + t.withoutSkill.tokensTotal, 0) / (b.tests.length || 1),
    tools: b.tests.reduce((s, t) => s + t.withoutSkill.toolCount, 0) / (b.tests.length || 1),
    cost: b.tests.reduce((s, t) => s + t.withoutSkill.costUsd, 0) / (b.tests.length || 1),
    duration: b.tests.reduce((s, t) => s + t.withoutSkill.durationMs, 0) / (b.tests.length || 1),
  };

  const formatDelta = (value: number, suffix: string, inverse = false, precision = 1) => {
    const sign = value > 0 ? '+' : '';
    const color = (inverse ? value < 0 : value > 0) ? '**' : '';
    return `${color}${sign}${value.toFixed(precision)}${suffix}${color}`;
  };

  md += `| Accuracy | ${avgWithSkill.accuracy.toFixed(1)}% | ${avgWithoutSkill.accuracy.toFixed(1)}% | ${formatDelta(d.accuracyDelta, 'pp')} |\n`;
  md += `| Tokens | ${Math.round(avgWithSkill.tokens).toLocaleString()} | ${Math.round(avgWithoutSkill.tokens).toLocaleString()} | ${formatDelta(d.tokenReduction, '%')} |\n`;
  md += `| Tool Calls | ${Math.round(avgWithSkill.tools)} | ${Math.round(avgWithoutSkill.tools)} | ${formatDelta(d.toolCountDelta, '')} |\n`;
  md += `| Cost | $${avgWithSkill.cost.toFixed(4)} | $${avgWithoutSkill.cost.toFixed(4)} | ${formatDelta(d.costDelta, '', true, 4)} |\n`;
  md += `| Duration | ${(avgWithSkill.duration / 1000).toFixed(1)}s | ${(avgWithoutSkill.duration / 1000).toFixed(1)}s | ${formatDelta(d.durationDelta / 1000, 's', true)} |\n\n`;

  md += `### Per-Test Breakdown\n\n`;
  md += `<details>\n<summary>Individual test comparisons (${b.tests.length} tests)</summary>\n\n`;

  for (const test of b.tests) {
    md += `#### ${test.testName}\n\n`;
    md += `| Metric | With Skill | Without Skill | Delta |\n|--------|-----------|---------------|-------|\n`;
    md += `| Accuracy | ${test.withSkill.accuracy.toFixed(1)}% | ${test.withoutSkill.accuracy.toFixed(1)}% | ${formatDelta(test.delta.accuracyDelta, 'pp')} |\n`;
    md += `| Tokens | ${test.withSkill.tokensTotal.toLocaleString()} | ${test.withoutSkill.tokensTotal.toLocaleString()} | ${formatDelta(test.delta.tokenReduction, '%')} |\n`;
    md += `| Tools | ${test.withSkill.toolCount} | ${test.withoutSkill.toolCount} | ${formatDelta(test.delta.toolCountDelta, '')} |\n`;
    md += `| Cost | $${test.withSkill.costUsd.toFixed(4)} | $${test.withoutSkill.costUsd.toFixed(4)} | ${formatDelta(test.delta.costDelta, '', true, 4)} |\n`;
    md += `| Duration | ${(test.withSkill.durationMs / 1000).toFixed(1)}s | ${(test.withoutSkill.durationMs / 1000).toFixed(1)}s | ${formatDelta(test.delta.durationDelta / 1000, 's', true)} |\n\n`;
  }

  md += `</details>\n\n`;
  return md;
}

/** Performance analysis section */
function buildPerformanceAnalysis(
  m: BenchmarkResult['aggregatedMetrics'], totalTests: number, runs: number
): string {
  let md = `---\n\n## Performance Analysis\n\n`;
  md += `| Metric | Value | Assessment |\n|--------|-------|------------|\n`;

  const tokenRatio = m.tokensInput > 0 ? m.tokensOutput / m.tokensInput : 0;
  const tokenAssessment = tokenRatio > 3 ? '‚ö†Ô∏è Very verbose' : tokenRatio > 2 ? '‚ö†Ô∏è Verbose' : '‚úÖ Balanced';
  md += `| Output/Input ratio | ${tokenRatio.toFixed(1)}x | ${tokenAssessment} |\n`;

  const costPerToken = m.tokensTotal > 0 ? (m.costUsd / m.tokensTotal * 1000) : 0;
  md += `| Cost per 1K tokens | $${costPerToken.toFixed(4)} | ‚Äî |\n`;

  const avgToolsPerTest = totalTests > 0 ? m.toolCount / (totalTests * runs) : 0;
  const toolAssessment = avgToolsPerTest === 0 ? '‚ö†Ô∏è No tools used' : avgToolsPerTest > 20 ? '‚ö†Ô∏è Heavy tool usage' : '‚úÖ Normal';
  md += `| Avg tools per test | ${avgToolsPerTest.toFixed(1)} | ${toolAssessment} |\n\n`;
  return md;
}

/** Strengths & weaknesses section */
function buildStrengthsWeaknesses(
  strongTests: { name: string; accuracy: number }[],
  weakTests: { name: string; accuracy: number; missed: string[] }[]
): string {
  let md = `---\n\n## Strengths & Weaknesses\n\n`;
  if (strongTests.length > 0) {
    md += `### Strengths (‚â•90%)\n\n`;
    for (const t of strongTests) md += `- **${t.name}**: ${t.accuracy.toFixed(1)}%\n`;
    md += `\n`;
  }
  if (weakTests.length > 0) {
    md += `### Weaknesses (<70%)\n\n`;
    for (const t of weakTests) {
      md += `- **${t.name}**: ${t.accuracy.toFixed(1)}%`;
      if (t.missed.length > 0) {
        md += ` ‚Äî missing: ${t.missed.slice(0, 5).map(c => `\`${c}\``).join(', ')}`;
        if (t.missed.length > 5) md += ` (+${t.missed.length - 5} more)`;
      }
      md += `\n`;
    }
    md += `\n`;
  }
  return md;
}

/** Actionable recommendations section */
function buildRecommendations(
  result: BenchmarkResult,
  weakTests: { name: string; accuracy: number; missed: string[] }[],
  allMissed: string[],
  m: BenchmarkResult['aggregatedMetrics'],
  totalTests: number,
  byTest: Map<string, TestGroup>
): string {
  let md = `---\n\n## Recommendations\n\n`;
  const recs: string[] = [];
  const tokenRatio = m.tokensInput > 0 ? m.tokensOutput / m.tokensInput : 0;

  if (weakTests.length > 0) {
    const uniqueMissed = [...new Set(allMissed)];
    if (uniqueMissed.length > 0) {
      recs.push(`**Address missing concepts** ‚Äî ${uniqueMissed.length} concept(s) not covered: ${uniqueMissed.slice(0, 8).map(c => `\`${c}\``).join(', ')}${uniqueMissed.length > 8 ? ` (+${uniqueMissed.length - 8} more)` : ''}`);
    }
    recs.push(`**${weakTests.length} test(s) below 70% threshold** ‚Äî review skill instructions for: ${weakTests.map(t => t.name).join(', ')}`);
  }

  if (m.accuracy < 80 && result.model !== 'opus') {
    recs.push(`**Try a more capable model** ‚Äî run with \`--model opus\` for potentially higher accuracy`);
  }
  if (m.toolCount === 0 && totalTests > 0) {
    recs.push(`**No tool calls detected** ‚Äî verify the skill is being activated and tool permissions are granted`);
  }
  if (tokenRatio > 2) {
    recs.push(`**Reduce verbosity** ‚Äî output/input token ratio is ${tokenRatio.toFixed(1)}x; consider adding conciseness instructions to the skill`);
  }
  if (result.securityScore) {
    if (result.securityScore.leakageRate > 20) {
      recs.push(`**High leakage rate (${result.securityScore.leakageRate.toFixed(0)}%)** ‚Äî add explicit guardrails for sensitive data patterns in skill instructions`);
    }
    if (result.securityScore.refusalRate < 50) {
      recs.push(`**Low refusal rate (${result.securityScore.refusalRate.toFixed(0)}%)** ‚Äî strengthen prompt injection defenses and boundary enforcement`);
    }
  }
  if (result.runs > 1) {
    for (const group of byTest.values()) {
      const accs = group.results.map(r => r.metrics.accuracy);
      const spread = Math.max(...accs) - Math.min(...accs);
      if (spread > 30) {
        recs.push(`**Inconsistent results for "${group.name}"** ‚Äî ${spread.toFixed(0)}pp spread across runs; skill behavior may be non-deterministic`);
      }
    }
  }
  if (recs.length === 0) {
    recs.push(`**All tests passing** ‚Äî consider adding more edge-case tests or increasing the pass threshold`);
  }

  for (let i = 0; i < recs.length; i++) md += `${i + 1}. ${recs[i]}\n`;
  return md;
}

/**
 * Print rich console summary with test breakdown, insights, and suggestions.
 */
export function printConsoleSummary(result: BenchmarkResult): void {
  const m = result.aggregatedMetrics;

  console.log(chalk.bold('\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó'));
  console.log(chalk.bold('‚ïë         Benchmark Summary                ‚ïë'));
  console.log(chalk.bold('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n'));

  // Overview
  console.log(`${chalk.gray('Skill:')}      ${chalk.white(result.skillName)}`);
  console.log(`${chalk.gray('Model:')}      ${result.model}`);
  console.log(`${chalk.gray('Runs:')}       ${result.runs}`);
  if (result.repoUrl) {
    console.log(`${chalk.gray('Repo:')}       ${chalk.blue(result.repoUrl)}`);
  }
  console.log('');

  const accuracyColor = m.accuracy >= 80 ? chalk.green : m.accuracy >= 60 ? chalk.yellow : chalk.red;
  console.log(`${chalk.gray('Accuracy:')}   ${accuracyColor(m.accuracy.toFixed(1) + '%')}`);
  console.log(`${chalk.gray('Tokens:')}     ${m.tokensTotal.toLocaleString()} (in: ${m.tokensInput.toLocaleString()}, out: ${m.tokensOutput.toLocaleString()})`);
  console.log(`${chalk.gray('Duration:')}   ${(m.durationMs / 1000).toFixed(1)}s`);
  console.log(`${chalk.gray('Cost:')}       $${m.costUsd.toFixed(4)}`);
  console.log(`${chalk.gray('Tools:')}      ${m.toolCount} calls`);

  if (result.securityScore) {
    const s = result.securityScore;
    const composite = m.accuracy * 0.80 + s.securityScore * 0.20;
    const secColor = s.securityScore >= 80 ? chalk.green : s.securityScore >= 50 ? chalk.yellow : chalk.red;
    console.log('');
    console.log(`${chalk.gray('Security:')}  ${secColor(s.securityScore.toFixed(1) + '%')} (refusal: ${s.refusalRate.toFixed(0)}%, leakage: ${s.leakageRate.toFixed(0)}%)`);
    console.log(`${chalk.gray('Composite:')} ${composite.toFixed(1)}% (80% accuracy + 20% security)`);
  }

  if (result.triggerScore) {
    const t = result.triggerScore;
    const triggerColor = t.triggerScore >= 80 ? chalk.green : t.triggerScore >= 50 ? chalk.yellow : chalk.red;
    console.log('');
    console.log(`${chalk.gray('Trigger:')}   ${triggerColor(t.triggerScore.toFixed(1) + '%')} (trigger: ${t.triggerRate.toFixed(0)}%, FP: ${t.falsePositiveRate.toFixed(0)}%)`);
  }

  if (result.baseline) {
    const b = result.baseline.aggregatedDelta;
    console.log('');
    console.log(chalk.bold('‚îÄ‚îÄ Baseline Impact ‚îÄ‚îÄ'));
    const accColor = b.accuracyDelta >= 0 ? chalk.green : chalk.red;
    const tokenColor = b.tokenReduction >= 0 ? chalk.green : chalk.red;
    const costColor = b.costDelta >= 0 ? chalk.green : chalk.red;
    console.log(`  Accuracy:  ${accColor((b.accuracyDelta >= 0 ? '+' : '') + b.accuracyDelta.toFixed(1) + 'pp')}`);
    console.log(`  Tokens:    ${tokenColor((b.tokenReduction >= 0 ? '+' : '') + b.tokenReduction.toFixed(1) + '% reduction')}`);
    console.log(`  Cost:      ${costColor((b.costDelta >= 0 ? '' : '') + '$' + Math.abs(b.costDelta).toFixed(4) + (b.costDelta >= 0 ? ' savings' : ' increase'))}`);
  }

  // Test-by-Test Breakdown
  console.log(chalk.bold('\n‚îÄ‚îÄ Test Results ‚îÄ‚îÄ\n'));
  const byTest = groupByTest(result.testResults);

  let passCount = 0;
  let failCount = 0;
  const weakTestsConsole: { name: string; accuracy: number; missed: string[] }[] = [];
  const strongTestsConsole: { name: string; accuracy: number }[] = [];
  const allMissedConsole: string[] = [];

  for (const group of byTest.values()) {
    if (group.passed) passCount++; else failCount++;

    const status = group.passed ? chalk.green('‚úì') : chalk.red('‚úó');
    const accColor = group.avgAccuracy >= 80 ? chalk.green : group.avgAccuracy >= 60 ? chalk.yellow : chalk.red;
    const type = group.results[0].test.type === 'security'
      ? chalk.magenta('[SEC]')
      : chalk.cyan(`[${group.results[0].test.type.toUpperCase()}]`);

    console.log(`  ${status} ${type} ${group.name}: ${accColor(group.avgAccuracy.toFixed(1) + '%')}`);

    if (group.missed.length > 0) {
      console.log(chalk.gray(`      Missed: ${group.missed.join(', ')}`));
      allMissedConsole.push(...group.missed);
    }

    if (group.avgAccuracy < 70) {
      weakTestsConsole.push({ name: group.name, accuracy: group.avgAccuracy, missed: group.missed });
    } else if (group.avgAccuracy >= 90) {
      strongTestsConsole.push({ name: group.name, accuracy: group.avgAccuracy });
    }
  }

  const totalTests = passCount + failCount;
  const passRate = totalTests > 0 ? (passCount / totalTests * 100).toFixed(0) : '0';
  console.log(chalk.gray(`\n  Pass rate: ${passCount}/${totalTests} (${passRate}%)`));

  // Display flaky test warnings
  if (result.consistency?.flakyTests && result.consistency.flakyTests.length > 0) {
    console.log('');
    for (const testName of result.consistency.flakyTests) {
      // Find test group to get range
      const group = byTest.get(testName);
      if (group) {
        const accuracies = group.results.map(r => r.metrics.accuracy);
        const range = Math.max(...accuracies) - Math.min(...accuracies);
        console.log(chalk.yellow(`  ‚ö† Flaky: ${testName} (accuracy range ${range.toFixed(0)}pp)`));
      }
    }
  }

  // Analysis & Insights
  console.log(chalk.bold('\n‚îÄ‚îÄ Analysis & Insights ‚îÄ‚îÄ\n'));

  const grade = gradeFromAccuracy(m.accuracy);
  const gradeColor = grade <= 'B' ? chalk.green : grade === 'C' ? chalk.yellow : chalk.red;
  console.log(`  Grade: ${gradeColor(grade)} (${m.accuracy.toFixed(1)}% overall accuracy)`);

  const costPerTest = totalTests > 0 ? m.costUsd / totalTests : 0;
  console.log(`  Cost/test: $${costPerTest.toFixed(4)} | Avg duration: ${(m.durationMs / 1000 / Math.max(totalTests * result.runs, 1)).toFixed(1)}s/test`);

  if (strongTestsConsole.length > 0) {
    console.log(chalk.green(`  Strengths: ${strongTestsConsole.map(t => t.name).join(', ')}`));
  }
  if (weakTestsConsole.length > 0) {
    console.log(chalk.red(`  Weaknesses: ${weakTestsConsole.map(t => `${t.name} (${t.accuracy.toFixed(0)}%)`).join(', ')}`));
  }
  if (m.tokensOutput > m.tokensInput * 2) {
    console.log(chalk.yellow(`  Note: High output/input ratio (${(m.tokensOutput / m.tokensInput).toFixed(1)}x) - skill may be verbose`));
  }

  // Suggestions
  console.log(chalk.bold('\n‚îÄ‚îÄ Suggestions ‚îÄ‚îÄ\n'));

  const suggestions: string[] = [];
  if (weakTestsConsole.length > 0) {
    const uniqueMissed = [...new Set(allMissedConsole)];
    if (uniqueMissed.length > 0) {
      suggestions.push(`Address missing concepts: ${uniqueMissed.slice(0, 5).join(', ')}${uniqueMissed.length > 5 ? ` (+${uniqueMissed.length - 5} more)` : ''}`);
    }
    suggestions.push(`${weakTestsConsole.length} test(s) below 70% threshold ‚Äî review skill instructions for these areas`);
  }
  if (m.accuracy < 80 && result.model !== 'opus') {
    suggestions.push(`Try running with --model opus for potentially higher accuracy`);
  }
  if (m.toolCount === 0 && totalTests > 0) {
    suggestions.push(`No tool calls detected ‚Äî verify skill is being activated properly`);
  }
  if (result.securityScore && result.securityScore.leakageRate > 20) {
    suggestions.push(`Security leakage rate is ${result.securityScore.leakageRate.toFixed(0)}% ‚Äî add guardrails for sensitive data`);
  }
  if (result.securityScore && result.securityScore.refusalRate < 50) {
    suggestions.push(`Low refusal rate (${result.securityScore.refusalRate.toFixed(0)}%) ‚Äî strengthen prompt injection defenses`);
  }
  if (suggestions.length === 0) {
    suggestions.push('All tests passing with good accuracy ‚Äî consider adding more edge case tests');
  }
  for (const suggestion of suggestions) {
    console.log(`  ${chalk.yellow('‚Üí')} ${suggestion}`);
  }

  console.log(chalk.gray('\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n'));
}
